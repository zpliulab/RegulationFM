import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import numpy as np
# from scipy.sparse import csr_matrix
from torch.utils.data import DataLoader, TensorDataset
from multiomics_integration import VAE, loss_function, multi_view_nmf, construct_laplacian
from tqdm import tqdm

def train_vae(model, data_loader, epochs=20, lr=1e-3, beta=1, device='cpu'):
    # optimizer = optim.Adam(model.parameters(), lr=lr)
    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=5e-4)  # 定义优化器
    model = model.to(device)
    progress_bar = tqdm(range(epochs), ncols=100, desc='Training VAE modell')
    for epoch in progress_bar:
        model.train()
        train_loss = 0
        for batch_idx, data in enumerate(data_loader):
            data = data[0]
            data = data.to(device)
            optimizer.zero_grad()
            recon_batch, mu, logvar = model(data)
            loss = loss_function(recon_batch, data, mu, logvar, beta=beta)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            train_loss += loss.item()
            optimizer.step()
        progress_bar.set_postfix({'Epoch': f'{epoch+1:d}', 'Loss': f'{train_loss / len(data_loader.dataset):.4f}'})

    return model

def weights_init(m):
    if isinstance(m, nn.Linear):
        nn.init.kaiming_normal_(m.weight)
        nn.init.constant_(m.bias, 0)

class Multiomics_joint:
    def __init__(self, n_views, input_dims, latent_dim=10, nmf_rank=5, alpha=0.1, beta=1, n_iter=100, device='cpu'):
        self.n_views = n_views
        self.vae_models = [VAE(input_dim=dim, latent_dim=latent_dim).to(device) for dim in input_dims]
        for model in self.vae_models:
            model.apply(weights_init)
        self.nmf_rank = nmf_rank
        self.alpha = alpha
        self.beta = beta
        self.n_iter = n_iter
        self.device = device

    def train_vae(self, datasets, batchsize=64, epochs=20, lr=1e-3):
        data_loaders = [DataLoader(TensorDataset(torch.tensor(X, dtype=torch.float32)),
                                   batch_size=batchsize, shuffle=True) for X in datasets]
        for i in range(self.n_views):
            self.vae_models[i] = train_vae(self.vae_models[i], data_loaders[i], epochs, lr, self.beta, device=self.device)

    def get_latent_representations(self, datasets):
        latent_representations = []
        for vae, X in zip(self.vae_models, datasets):
            X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)
            with torch.no_grad():
                mu, logvar = vae.encode(X_tensor)
                z = vae.reparameterize(mu, logvar)
                latent_representations.append(z.cpu().detach().numpy())

        return latent_representations

    def get_reconstructed_data(self, datasets):
        """
        获取每个视图数据的VAE重构数据
        :param vae_models: 已训练的VAE模型列表
        :param datasets: 原始数据集
        :return: 重构数据列表
        """
        reconstructed_datasets = []
        for vae, X in zip(self.vae_models, datasets):
            X_tensor = torch.tensor(X, dtype=torch.float32)
            with torch.no_grad():
                recon, _, _ = vae(X_tensor)
                reconstructed_datasets.append(recon.numpy())

        return reconstructed_datasets

    def fit(self, datasets, batchsize=64, epochs=20, lr=1e-3, graph_file=None):
        """
        Train VAE and use the reconstructed data as input to NMF
        :param datasets: original multimodal dataset
        :param epochs: number of epochs for VAE training
        :param lr: learning rate
        :param gamma: Gaussian kernel parameter for graph regularization
        :return: shared representation H and specific representation W_s, W_v, V generated by iNMF
        """
        # 训练VAE
        print("INFO:: Start training the VAE model independently...")
        self.train_vae(datasets, epochs=epochs, lr=lr, batchsize=batchsize)

        # 使用VAE对每个视图进行重构
        reconstructed_datasets = []
        for vae, X in zip(self.vae_models, datasets):
            X_tensor = torch.tensor(X, dtype=torch.float32, device=self.device)
            with torch.no_grad():
                recon_X, _, _ = vae(X_tensor)
            reconstructed_datasets.append(recon_X.cpu().detach().numpy())

        print("INFO:: Run iNMF algorithm...")
        laplacians = construct_laplacian(graph_file=graph_file, device=self.device)
        latent_datasets = self.get_latent_representations(datasets)
        H, W, V = multi_view_nmf(latent_datasets,
                                        laplacians,
                                        rank=self.nmf_rank,
                                        alpha=self.alpha,
                                        n_iter=self.n_iter,
                                        device=self.device)
        print('Finishing!')
        self.H = H
        self.V_list = V
        self.L_list = latent_datasets

        return H, W, V, latent_datasets

    def get_final_representation(self, dataset_names=None, genename=None, save_path=None, file_label="/joint_represent_input.h5"):
        """
        Returns the final combined representation after training, aligned by row names.
        If row names don't match, it will fill the missing parts with zeros.
        """

        # Concatenate the final representations
        All_data = []
        if save_path is not None:
            with pd.HDFStore(save_path+file_label) as store:
                for name, V1, L1 in zip(dataset_names, self.V_list, self.L_list):
                    Omics_single = np.hstack((V1, L1))
                    Omics_single = pd.DataFrame(Omics_single, index=genename)
                    store.put(name.replace('/', ''), Omics_single)
                    All_data.append(Omics_single)
                share_rep = pd.DataFrame(self.H, index=genename)
                store.put('Omics_share', share_rep)
                All_data.append(share_rep)
            print(f'INFO:: file save at {save_path}{file_label}!')
        return All_data
